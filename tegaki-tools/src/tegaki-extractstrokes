#!/usr/bin/python
# -*- coding: utf-8 -*-
# Copyright (C) 2009 The Tegaki project contributors
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

# Contributors to this file:
# - Christoph Burgmer, cburgmer ÂT ira DÔT uka DÔT de (main author)
# - Mathieu Blondel

"""
Extract single stroke handwriting data and build a character collection for
stroke handwriting.
"""

import sys
from optparse import OptionParser

from tegaki.character import CharacterCollection, Character, Writing
from tegakitools.tomoe import tomoe_dict_to_character_collection
from tegakitools.kuchibue import kuchibue_to_character_collection

try:
    from cjklib.characterlookup import CharacterLookup
    from cjklib.exception import NoInformationError
except ImportError:
    print "Please install cjklib (http://code.google.com/p/cjklib)"
    sys.exit(1)

VERSION = '0.3'

class TegakiExtractStrokes(object):

    def __init__(self, options, args):
        self._directories = options.directories
        self._charcols = options.charcols
        self._tomoe = options.tomoe
        self._kuchibue = options.kuchibue
        self._include = options.include
        self._exclude = options.exclude
        self._max_samples = options.max_samples
        self._locale = options.locale
        self._quiet = options.quiet

        try:
            self._output_path = args[0]
        except:
            self._output_path = None

        self._cjk = CharacterLookup(self._locale)

    def _get_charcol(self):
        if not hasattr(self, '_charcol'):
            self._charcol = CharacterCollection()

            # add the directories provided
            for directory in self._directories:
                self._charcol += CharacterCollection.from_character_directory(
                    directory)

            # add the character collections provided
            for charcol_path in self._charcols:
                _charcol = CharacterCollection()
                gzip = False; bz2 = False
                if charcol_path.endswith(".gz"): gzip = True
                if charcol_path.endswith(".bz2"): bz2 = True
                _charcol.read(charcol_path, gzip=gzip, bz2=bz2)
                self._charcol += _charcol

            # add tomoe dictionaries provided
            for tomoe in self._tomoe:
                self._charcol += tomoe_dict_to_character_collection(tomoe)

            # add the kuchibue databases provided
            for kuchibue in self._kuchibue:
                self._charcol += kuchibue_to_character_collection(kuchibue)

            # characters to include
            buf = ""
            for inc_path in self._include:
                f = open(inc_path)
                buf += f.read()
                f.close()

            if len(buf) > 0:
                self._charcol.include_characters_from_text(buf)

            # characters to exclude
            buf = ""
            for exc_path in self._exclude:
                f = open(exc_path)
                buf += f.read()
                f.close()

            if len(buf) > 0:
                self._charcol.exclude_characters_from_text(buf)

            # max samples
            if self._max_samples:
                self._charcol.remove_samples(keep_at_most=self._max_samples)

        return self._charcol

    def run(self):
        charcol = self._get_charcol()

        # do the bootstrapping
        to_charcol = self.extract_strokes(charcol)

        # output
        if not self._output_path:
            # outputs to stdout if no output path specified
            print to_charcol.to_xml()
        else:
            gzip = False; bz2 = False
            if self._output_path.endswith(".gz"): gzip = True
            if self._output_path.endswith(".bz2"): bz2 = True
            to_charcol.write(self._output_path, gzip=gzip, bz2=bz2)

    def extract_strokes(self, charcol):
        to_charcol = CharacterCollection()
        stroke_count = {}

        for char in charcol.get_all_characters():
            for stroke in self.get_stroke_writings(char):
                codepoint = stroke.get_utf8()
                # obey max samples
                if stroke_count.get(codepoint, 0) < self._max_samples:
                    to_charcol.append_character(codepoint, stroke)
                    stroke_count[codepoint] = stroke_count.get(codepoint, 0) + 1

        return to_charcol

    def get_stroke_writings(self, char):
        """
        Gets a list of Character objects with extracted component handwriting
        data for the given char.
        """
        c = char.get_unicode()
        writing = char.get_writing()

        try:
            stroke_order = self._cjk.getStrokeOrder(c)

            if len(stroke_order) != writing.get_n_strokes():
                if not self._quiet:
                    print >> sys.stderr, (
                          "Stroke count doesn't match for %s" % c
                          + " (cjklib %d, handwriting writing %d)"
                          % (len(stroke_order), writing.get_n_strokes()))
                return []

            return self._get_writings(stroke_order, writing)
        except NoInformationError:
            return []

    def _get_writings(self, strokeOrder, sourceWriting):
        """
        Returns a list of Character objects with extracted stroke handwriting
        data.
        """
        stroke_writing_list = []

        strokeData = sourceWriting.get_strokes(True)
        for idx, stroke in enumerate(strokeOrder):
            writing = Writing()
            writing.append_stroke(strokeData[idx])
            #writing.normalize()
            writing.normalize_position()

            new_char = Character()
            new_char.set_unicode(stroke)
            new_char.set_writing(writing)

            stroke_writing_list.append(new_char)

        return stroke_writing_list


parser = OptionParser(usage="usage: %prog [options] [output-path]",
                      version="%prog " + VERSION)

parser.add_option("-d", "--directory",
                  action="append", type="string", dest="directories",
                  default=[],
                  help="Directory containing individual XML character files")
parser.add_option("-c", "--charcol",
                  action="append", type="string", dest="charcols",
                  default=[],
                  help="character collection XML files")
parser.add_option("-t", "--tomoe-dict",
                  action="append", type="string", dest="tomoe",
                  default=[],
                  help="Tomoe XML dictionary files")
parser.add_option("-k", "--kuchibue",
                  action="append", type="string", dest="kuchibue",
                  default=[],
                  help="Kuchibue unipen database")


parser.add_option("-i", "--include",
                  action="append", type="string", dest="include",
                  default=[],
                  help="File containing characters to include")
parser.add_option("-e", "--exclude",
                  action="append", type="string", dest="exclude",
                  default=[],
                  help="File containing characters to exclude")


parser.add_option("-m", "--max-samples",
                  type="int", dest="max_samples",
                  help="Maximum number of samples per character")


parser.add_option("-l", "--locale",
                  type="string", dest="locale",
                  default='T',
                  help="Character locale of source characters")
parser.add_option("-q", "--quiet", dest="quiet",
                  action="store_true",
                  help="Don't print any statistics")

(options, args) = parser.parse_args()

#try:
TegakiExtractStrokes(options, args).run()
#except TegakiBootstrapError, e:
    #sys.stderr.write(str(e) + "\n\n")
    #parser.print_help()
    #sys.exit(1)
